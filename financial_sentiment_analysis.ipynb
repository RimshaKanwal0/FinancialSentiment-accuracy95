{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41f79768",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-08T17:56:19.980746Z",
          "iopub.status.busy": "2025-04-08T17:56:19.980354Z",
          "iopub.status.idle": "2025-04-08T17:56:22.612216Z",
          "shell.execute_reply": "2025-04-08T17:56:22.611455Z"
        },
        "papermill": {
          "duration": 2.638528,
          "end_time": "2025-04-08T17:56:22.613881",
          "exception": false,
          "start_time": "2025-04-08T17:56:19.975353",
          "status": "completed"
        },
        "tags": [],
        "id": "41f79768"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27526bc4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T17:56:22.622072Z",
          "iopub.status.busy": "2025-04-08T17:56:22.621584Z",
          "iopub.status.idle": "2025-04-08T17:56:38.145638Z",
          "shell.execute_reply": "2025-04-08T17:56:38.144662Z"
        },
        "papermill": {
          "duration": 15.52987,
          "end_time": "2025-04-08T17:56:38.147419",
          "exception": false,
          "start_time": "2025-04-08T17:56:22.617549",
          "status": "completed"
        },
        "tags": [],
        "id": "27526bc4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "706800bb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T17:56:38.155565Z",
          "iopub.status.busy": "2025-04-08T17:56:38.155023Z",
          "iopub.status.idle": "2025-04-08T17:56:42.833797Z",
          "shell.execute_reply": "2025-04-08T17:56:42.832746Z"
        },
        "papermill": {
          "duration": 4.684855,
          "end_time": "2025-04-08T17:56:42.835775",
          "exception": false,
          "start_time": "2025-04-08T17:56:38.150920",
          "status": "completed"
        },
        "tags": [],
        "id": "706800bb"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25aa1a0b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T17:56:42.844335Z",
          "iopub.status.busy": "2025-04-08T17:56:42.843606Z",
          "iopub.status.idle": "2025-04-08T17:56:42.903180Z",
          "shell.execute_reply": "2025-04-08T17:56:42.902100Z"
        },
        "papermill": {
          "duration": 0.065165,
          "end_time": "2025-04-08T17:56:42.904726",
          "exception": false,
          "start_time": "2025-04-08T17:56:42.839561",
          "status": "completed"
        },
        "tags": [],
        "id": "25aa1a0b",
        "outputId": "51788a20-029d-46d3-8ee6-668321571ff2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence Sentiment\n",
              "0  The GeoSolutions technology will leverage Bene...  positive\n",
              "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
              "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
              "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
              "4  The Swedish buyout firm has sold its remaining...   neutral"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/kaggle/input/financial-sentiment-analysis/data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da144cda",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T17:56:42.913000Z",
          "iopub.status.busy": "2025-04-08T17:56:42.912718Z",
          "iopub.status.idle": "2025-04-08T17:56:42.922712Z",
          "shell.execute_reply": "2025-04-08T17:56:42.921770Z"
        },
        "papermill": {
          "duration": 0.015611,
          "end_time": "2025-04-08T17:56:42.924034",
          "exception": false,
          "start_time": "2025-04-08T17:56:42.908423",
          "status": "completed"
        },
        "tags": [],
        "id": "da144cda",
        "outputId": "d6d20d48-19d9-4159-dce0-8f015ef04ee5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Sentiment\n",
              "0  The GeoSolutions technology will leverage Bene...          2\n",
              "1  $ESI on lows, down $1.50 to $2.50 BK a real po...          0\n",
              "2  For the last quarter of 2010 , Componenta 's n...          2\n",
              "3  According to the Finnish-Russian Chamber of Co...          1\n",
              "4  The Swedish buyout firm has sold its remaining...          1"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder = LabelEncoder()\n",
        "scaler = StandardScaler()\n",
        "df['Sentiment'] = encoder.fit_transform(df['Sentiment'])\n",
        "# df['Sentiment'] = scaler.fit_transform(df[['Sentiment']])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd004d0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T17:56:42.935841Z",
          "iopub.status.busy": "2025-04-08T17:56:42.935494Z",
          "iopub.status.idle": "2025-04-08T17:56:44.638005Z",
          "shell.execute_reply": "2025-04-08T17:56:44.636964Z"
        },
        "papermill": {
          "duration": 1.710907,
          "end_time": "2025-04-08T17:56:44.639650",
          "exception": false,
          "start_time": "2025-04-08T17:56:42.928743",
          "status": "completed"
        },
        "tags": [],
        "id": "9fd004d0",
        "outputId": "6c9fc7f8-13ff-4cbd-8466-e38fb2e8416a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>preprocessed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
              "      <td>2</td>\n",
              "      <td>geosolutions technology leverage benefon gps s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
              "      <td>0</td>\n",
              "      <td>esi lows bk real possibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>2</td>\n",
              "      <td>last quarter componenta net sales doubled eurm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
              "      <td>1</td>\n",
              "      <td>according finnishrussian chamber commerce majo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
              "      <td>1</td>\n",
              "      <td>swedish buyout firm sold remaining percent sta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Sentiment  \\\n",
              "0  The GeoSolutions technology will leverage Bene...          2   \n",
              "1  $ESI on lows, down $1.50 to $2.50 BK a real po...          0   \n",
              "2  For the last quarter of 2010 , Componenta 's n...          2   \n",
              "3  According to the Finnish-Russian Chamber of Co...          1   \n",
              "4  The Swedish buyout firm has sold its remaining...          1   \n",
              "\n",
              "                                   preprocessed_text  \n",
              "0  geosolutions technology leverage benefon gps s...  \n",
              "1                       esi lows bk real possibility  \n",
              "2  last quarter componenta net sales doubled eurm...  \n",
              "3  according finnishrussian chamber commerce majo...  \n",
              "4  swedish buyout firm sold remaining percent sta...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['preprocessed_text'] = df['Sentence'].apply(preprocess_text)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15a1b289",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T17:56:44.648466Z",
          "iopub.status.busy": "2025-04-08T17:56:44.648186Z",
          "iopub.status.idle": "2025-04-08T17:56:44.757667Z",
          "shell.execute_reply": "2025-04-08T17:56:44.756828Z"
        },
        "papermill": {
          "duration": 0.115916,
          "end_time": "2025-04-08T17:56:44.759514",
          "exception": false,
          "start_time": "2025-04-08T17:56:44.643598",
          "status": "completed"
        },
        "tags": [],
        "id": "15a1b289"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['preprocessed_text'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['Sentiment'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "442d203a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T17:56:44.768218Z",
          "iopub.status.busy": "2025-04-08T17:56:44.767939Z",
          "iopub.status.idle": "2025-04-08T17:56:44.777262Z",
          "shell.execute_reply": "2025-04-08T17:56:44.776369Z"
        },
        "papermill": {
          "duration": 0.014908,
          "end_time": "2025-04-08T17:56:44.778576",
          "exception": false,
          "start_time": "2025-04-08T17:56:44.763668",
          "status": "completed"
        },
        "tags": [],
        "id": "442d203a"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'Multinomial NB': MultinomialNB(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'LightGBM': LGBMClassifier(),\n",
        "    'CatBoost': CatBoostClassifier(logging_level='Silent')\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    'Logistic Regression': {\n",
        "        'C': [0.01, 0.1, 1, 10, 100],\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'solver': ['liblinear', 'saga']\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "        'max_features': ['sqrt', 'log2']\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'max_depth': [3, 5, 7]\n",
        "    },\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf', 'poly'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'Multinomial NB': {\n",
        "        'alpha': [0.1, 0.5, 1.0, 2.0]  # Smoothing parameter\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'subsample': [0.8, 1.0]\n",
        "    },\n",
        "    'LightGBM': {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [-1, 10, 20],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'num_leaves': [31, 50, 100]\n",
        "    },\n",
        "    'CatBoost': {\n",
        "        'iterations': [100, 200, 300],\n",
        "        'depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf4d697f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T17:56:44.786887Z",
          "iopub.status.busy": "2025-04-08T17:56:44.786632Z",
          "iopub.status.idle": "2025-04-08T17:59:03.933292Z",
          "shell.execute_reply": "2025-04-08T17:59:03.932140Z"
        },
        "papermill": {
          "duration": 139.155883,
          "end_time": "2025-04-08T17:59:03.938207",
          "exception": false,
          "start_time": "2025-04-08T17:56:44.782324",
          "status": "completed"
        },
        "tags": [],
        "id": "bf4d697f",
        "outputId": "4856b504-dc5e-45f9-afd7-ad996edf3621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Logistic Regression Results ---\n",
            "Accuracy: 0.699743370402053\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.15      0.22       175\n",
            "           1       0.69      0.90      0.78       622\n",
            "           2       0.77      0.63      0.69       372\n",
            "\n",
            "    accuracy                           0.70      1169\n",
            "   macro avg       0.63      0.56      0.57      1169\n",
            "weighted avg       0.68      0.70      0.67      1169\n",
            "\n",
            "\n",
            "--- Random Forest Results ---\n",
            "Accuracy: 0.6638152266894782\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.15      0.18       175\n",
            "           1       0.68      0.83      0.75       622\n",
            "           2       0.78      0.63      0.70       372\n",
            "\n",
            "    accuracy                           0.66      1169\n",
            "   macro avg       0.57      0.54      0.54      1169\n",
            "weighted avg       0.65      0.66      0.65      1169\n",
            "\n",
            "\n",
            "--- Gradient Boosting Results ---\n",
            "Accuracy: 0.6612489307100086\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.15      0.23       175\n",
            "           1       0.64      0.93      0.76       622\n",
            "           2       0.84      0.45      0.58       372\n",
            "\n",
            "    accuracy                           0.66      1169\n",
            "   macro avg       0.63      0.51      0.52      1169\n",
            "weighted avg       0.67      0.66      0.62      1169\n",
            "\n",
            "\n",
            "--- SVM Results ---\n",
            "Accuracy: 0.6903336184773311\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.10      0.16       175\n",
            "           1       0.67      0.93      0.78       622\n",
            "           2       0.83      0.57      0.68       372\n",
            "\n",
            "    accuracy                           0.69      1169\n",
            "   macro avg       0.62      0.53      0.54      1169\n",
            "weighted avg       0.68      0.69      0.65      1169\n",
            "\n",
            "\n",
            "--- Multinomial NB Results ---\n",
            "Accuracy: 0.69803250641574\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.07      0.13       175\n",
            "           1       0.69      0.95      0.80       622\n",
            "           2       0.73      0.57      0.64       372\n",
            "\n",
            "    accuracy                           0.70      1169\n",
            "   macro avg       0.71      0.53      0.52      1169\n",
            "weighted avg       0.71      0.70      0.65      1169\n",
            "\n",
            "\n",
            "--- XGBoost Results ---\n",
            "Accuracy: 0.6629597946963216\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.19      0.23       175\n",
            "           1       0.67      0.85      0.75       622\n",
            "           2       0.78      0.57      0.66       372\n",
            "\n",
            "    accuracy                           0.66      1169\n",
            "   macro avg       0.59      0.54      0.55      1169\n",
            "weighted avg       0.65      0.66      0.64      1169\n",
            "\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010477 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8420\n",
            "[LightGBM] [Info] Number of data points in the train set: 4673, number of used features: 446\n",
            "[LightGBM] [Info] Start training from score -1.920138\n",
            "[LightGBM] [Info] Start training from score -0.622316\n",
            "[LightGBM] [Info] Start training from score -1.149759\n",
            "\n",
            "--- LightGBM Results ---\n",
            "Accuracy: 0.6313088109495295\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.19      0.23       175\n",
            "           1       0.66      0.81      0.73       622\n",
            "           2       0.68      0.54      0.60       372\n",
            "\n",
            "    accuracy                           0.63      1169\n",
            "   macro avg       0.55      0.51      0.52      1169\n",
            "weighted avg       0.61      0.63      0.61      1169\n",
            "\n",
            "\n",
            "--- CatBoost Results ---\n",
            "Accuracy: 0.6903336184773311\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.17      0.25       175\n",
            "           1       0.68      0.90      0.77       622\n",
            "           2       0.79      0.58      0.67       372\n",
            "\n",
            "    accuracy                           0.69      1169\n",
            "   macro avg       0.64      0.55      0.56      1169\n",
            "weighted avg       0.68      0.69      0.66      1169\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n--- {name} Results ---\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2a0c47",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T17:59:03.948126Z",
          "iopub.status.busy": "2025-04-08T17:59:03.947776Z",
          "iopub.status.idle": "2025-04-08T20:42:20.733161Z",
          "shell.execute_reply": "2025-04-08T20:42:20.731916Z"
        },
        "papermill": {
          "duration": 9796.797117,
          "end_time": "2025-04-08T20:42:20.739766",
          "exception": false,
          "start_time": "2025-04-08T17:59:03.942649",
          "status": "completed"
        },
        "tags": [],
        "id": "4d2a0c47",
        "outputId": "0df7fec6-f8ef-48ec-eddc-a339376256ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "\n",
            "--- Logistic Regression Results ---\n",
            "Accuracy: 0.699743370402053\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.15      0.22       175\n",
            "           1       0.69      0.90      0.78       622\n",
            "           2       0.77      0.63      0.69       372\n",
            "\n",
            "    accuracy                           0.70      1169\n",
            "   macro avg       0.63      0.56      0.57      1169\n",
            "weighted avg       0.68      0.70      0.67      1169\n",
            "\n",
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
            "\n",
            "--- Random Forest Results ---\n",
            "Accuracy: 0.6928999144568007\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.11      0.18       175\n",
            "           1       0.69      0.91      0.78       622\n",
            "           2       0.73      0.61      0.66       372\n",
            "\n",
            "    accuracy                           0.69      1169\n",
            "   macro avg       0.64      0.54      0.54      1169\n",
            "weighted avg       0.67      0.69      0.65      1169\n",
            "\n",
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "\n",
            "--- Gradient Boosting Results ---\n",
            "Accuracy: 0.669803250641574\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.21      0.28       175\n",
            "           1       0.66      0.90      0.76       622\n",
            "           2       0.80      0.50      0.62       372\n",
            "\n",
            "    accuracy                           0.67      1169\n",
            "   macro avg       0.63      0.54      0.55      1169\n",
            "weighted avg       0.67      0.67      0.64      1169\n",
            "\n",
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "\n",
            "--- SVM Results ---\n",
            "Accuracy: 0.718562874251497\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.17      0.25       175\n",
            "           1       0.71      0.90      0.79       622\n",
            "           2       0.80      0.67      0.73       372\n",
            "\n",
            "    accuracy                           0.72      1169\n",
            "   macro avg       0.66      0.58      0.59      1169\n",
            "weighted avg       0.70      0.72      0.69      1169\n",
            "\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "\n",
            "--- Multinomial NB Results ---\n",
            "Accuracy: 0.7048759623609923\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.13      0.19       175\n",
            "           1       0.71      0.91      0.80       622\n",
            "           2       0.74      0.63      0.68       372\n",
            "\n",
            "    accuracy                           0.70      1169\n",
            "   macro avg       0.62      0.56      0.56      1169\n",
            "weighted avg       0.68      0.70      0.67      1169\n",
            "\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "\n",
            "--- XGBoost Results ---\n",
            "Accuracy: 0.6663815226689478\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.15      0.21       175\n",
            "           1       0.66      0.89      0.76       622\n",
            "           2       0.78      0.53      0.63       372\n",
            "\n",
            "    accuracy                           0.67      1169\n",
            "   macro avg       0.60      0.53      0.53      1169\n",
            "weighted avg       0.65      0.67      0.64      1169\n",
            "\n",
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007348 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8420\n",
            "[LightGBM] [Info] Number of data points in the train set: 4673, number of used features: 446\n",
            "[LightGBM] [Info] Start training from score -1.920138\n",
            "[LightGBM] [Info] Start training from score -0.622316\n",
            "[LightGBM] [Info] Start training from score -1.149759\n",
            "\n",
            "--- LightGBM Results ---\n",
            "Accuracy: 0.6629597946963216\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.11      0.19       175\n",
            "           1       0.64      0.95      0.76       622\n",
            "           2       0.78      0.45      0.57       372\n",
            "\n",
            "    accuracy                           0.66      1169\n",
            "   macro avg       0.66      0.50      0.51      1169\n",
            "weighted avg       0.67      0.66      0.62      1169\n",
            "\n",
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "\n",
            "--- CatBoost Results ---\n",
            "Accuracy: 0.688622754491018\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.18      0.26       175\n",
            "           1       0.67      0.92      0.78       622\n",
            "           2       0.78      0.55      0.65       372\n",
            "\n",
            "    accuracy                           0.69      1169\n",
            "   macro avg       0.65      0.55      0.56      1169\n",
            "weighted avg       0.68      0.69      0.66      1169\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, model in models.items():\n",
        "    param_grid = param_grids[name]\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n--- {name} Results ---\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5134677a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T20:42:20.750545Z",
          "iopub.status.busy": "2025-04-08T20:42:20.750235Z",
          "iopub.status.idle": "2025-04-08T20:46:58.966233Z",
          "shell.execute_reply": "2025-04-08T20:46:58.965379Z"
        },
        "papermill": {
          "duration": 278.223246,
          "end_time": "2025-04-08T20:46:58.967759",
          "exception": false,
          "start_time": "2025-04-08T20:42:20.744513",
          "status": "completed"
        },
        "tags": [],
        "id": "5134677a",
        "outputId": "efdf9944-f9a9-423f-bec8-11edac273e53",
        "colab": {
          "referenced_widgets": [
            "4f15966bcafd4453b683cd275de69e01",
            "0e7f9c0394d24d1184f3d42d40f4f6c8",
            "6fece39d170c46a089a19508c0fed9ff",
            "fe4f74f5819d432594c2cc50852b246b",
            "f8d47cc4830641c5b9926db8ad92634c"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f15966bcafd4453b683cd275de69e01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e7f9c0394d24d1184f3d42d40f4f6c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fece39d170c46a089a19508c0fed9ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe4f74f5819d432594c2cc50852b246b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4673 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8d47cc4830641c5b9926db8ad92634c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1169 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1755' max='1755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1755/1755 03:54, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.506800</td>\n",
              "      <td>0.566238</td>\n",
              "      <td>0.773311</td>\n",
              "      <td>{'0': {'precision': 0.5043478260869565, 'recall': 0.6628571428571428, 'f1-score': 0.5728395061728395, 'support': 175}, '1': {'precision': 0.8925143953934741, 'recall': 0.747588424437299, 'f1-score': 0.8136482939632544, 'support': 622}, '2': {'precision': 0.7727272727272727, 'recall': 0.8682795698924731, 'f1-score': 0.8177215189873417, 'support': 372}, 'accuracy': 0.7733105218135158, 'macro avg': {'precision': 0.7231964980692345, 'recall': 0.7595750457289716, 'f1-score': 0.7347364397078119, 'support': 1169}, 'weighted avg': {'precision': 0.7962868853331939, 'recall': 0.7733105218135158, 'f1-score': 0.7788952587584964, 'support': 1169}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.218900</td>\n",
              "      <td>0.527510</td>\n",
              "      <td>0.816938</td>\n",
              "      <td>{'0': {'precision': 0.7424242424242424, 'recall': 0.28, 'f1-score': 0.40663900414937765, 'support': 175}, '1': {'precision': 0.8035714285714286, 'recall': 0.9405144694533762, 'f1-score': 0.8666666666666667, 'support': 622}, '2': {'precision': 0.856, 'recall': 0.8629032258064516, 'f1-score': 0.859437751004016, 'support': 372}, 'accuracy': 0.8169375534644996, 'macro avg': {'precision': 0.8006652236652236, 'recall': 0.6944725650866093, 'f1-score': 0.71091447394002, 'support': 1169}, 'weighted avg': {'precision': 0.8111015149663567, 'recall': 0.8169375534644996, 'f1-score': 0.7954998595092402, 'support': 1169}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.316900</td>\n",
              "      <td>0.621851</td>\n",
              "      <td>0.791275</td>\n",
              "      <td>{'0': {'precision': 0.48223350253807107, 'recall': 0.5428571428571428, 'f1-score': 0.510752688172043, 'support': 175}, '1': {'precision': 0.8568994889267462, 'recall': 0.8086816720257235, 'f1-score': 0.8320926385442515, 'support': 622}, '2': {'precision': 0.8493506493506493, 'recall': 0.8790322580645161, 'f1-score': 0.8639365918097754, 'support': 372}, 'accuracy': 0.7912745936698032, 'macro avg': {'precision': 0.7294945469384887, 'recall': 0.7435236909824607, 'f1-score': 0.7355939728420232, 'support': 1169}, 'weighted avg': {'precision': 0.7984095693884005, 'recall': 0.7912745936698032, 'f1-score': 0.7941212606996308, 'support': 1169}}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- FinBERT Results ---\n",
            "Accuracy: 0.8169375534644996\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.28      0.41       175\n",
            "           1       0.80      0.94      0.87       622\n",
            "           2       0.86      0.86      0.86       372\n",
            "\n",
            "    accuracy                           0.82      1169\n",
            "   macro avg       0.80      0.69      0.71      1169\n",
            "weighted avg       0.81      0.82      0.80      1169\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/kaggle/input/financial-sentiment-analysis/data.csv')\n",
        "encoder = LabelEncoder()\n",
        "df['Sentiment'] = encoder.fit_transform(df['Sentiment'])\n",
        "\n",
        "# Split data\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df[['Sentence', 'Sentiment']].rename(columns={'Sentence': 'text', 'Sentiment': 'label'}))\n",
        "test_dataset = Dataset.from_pandas(test_df[['Sentence', 'Sentiment']].rename(columns={'Sentence': 'text', 'Sentiment': 'label'}))\n",
        "\n",
        "# Load FinBERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
        "model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', num_labels=3)\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Define compute_metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    report = classification_report(labels, predictions, output_dict=True)\n",
        "    return {'accuracy': accuracy, 'report': report}\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    report_to='none'  # Disable wandb logging\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Training model...\")\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate\n",
        "print(\"Evaluating model...\")\n",
        "eval_results = trainer.evaluate()\n",
        "accuracy = eval_results['eval_accuracy']\n",
        "print(f\"\\n--- FinBERT Results ---\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Predict and get detailed report\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis=-1)\n",
        "y_test = test_dataset['label']\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e63ba39",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T20:46:58.980647Z",
          "iopub.status.busy": "2025-04-08T20:46:58.980347Z",
          "iopub.status.idle": "2025-04-08T20:52:47.917175Z",
          "shell.execute_reply": "2025-04-08T20:52:47.916224Z"
        },
        "papermill": {
          "duration": 348.944746,
          "end_time": "2025-04-08T20:52:47.918654",
          "exception": false,
          "start_time": "2025-04-08T20:46:58.973908",
          "status": "completed"
        },
        "tags": [],
        "id": "6e63ba39",
        "outputId": "d848a9a5-890f-4e45-f60d-dc3585ba24f6",
        "colab": {
          "referenced_widgets": [
            "cdf1fa888fbd42748da4b0036f9b7802",
            "a5902d509e4941fa9ef71db673b183e6",
            "c71bd7364dcf4e599260233247c3e98b",
            "cce7d9d1addf4c3ea96b7226180268a8",
            "2c0792f4c9a4486c92317b8d3146f6ae",
            "4f544f1411ee46d78ba34a057d1be636",
            "e03a24677e414dba89035115dc0b5f40",
            "2164fc1ca12d41c192698be7bc2f01f5"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdf1fa888fbd42748da4b0036f9b7802",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5902d509e4941fa9ef71db673b183e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c71bd7364dcf4e599260233247c3e98b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cce7d9d1addf4c3ea96b7226180268a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c0792f4c9a4486c92317b8d3146f6ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f544f1411ee46d78ba34a057d1be636",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e03a24677e414dba89035115dc0b5f40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4673 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2164fc1ca12d41c192698be7bc2f01f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1169 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1465' max='1465' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1465/1465 05:31, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.532511</td>\n",
              "      <td>0.792985</td>\n",
              "      <td>{'0': {'precision': 0.5303030303030303, 'recall': 0.8, 'f1-score': 0.6378132118451025, 'support': 175}, '1': {'precision': 0.9212121212121213, 'recall': 0.7331189710610932, 'f1-score': 0.8164726947179947, 'support': 622}, '2': {'precision': 0.8073170731707318, 'recall': 0.8897849462365591, 'f1-score': 0.8465473145780051, 'support': 372}, 'accuracy': 0.7929854576561164, 'macro avg': {'precision': 0.7529440748952944, 'recall': 0.8076346390992174, 'f1-score': 0.766944407047034, 'support': 1169}, 'weighted avg': {'precision': 0.8264490341458356, 'recall': 0.7929854576561164, 'f1-score': 0.7992976297780183, 'support': 1169}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.382200</td>\n",
              "      <td>0.546409</td>\n",
              "      <td>0.818648</td>\n",
              "      <td>{'0': {'precision': 0.5504201680672269, 'recall': 0.7485714285714286, 'f1-score': 0.6343825665859565, 'support': 175}, '1': {'precision': 0.903107861060329, 'recall': 0.7942122186495176, 'f1-score': 0.8451668092386654, 'support': 622}, '2': {'precision': 0.8645833333333334, 'recall': 0.8924731182795699, 'f1-score': 0.8783068783068784, 'support': 372}, 'accuracy': 0.8186484174508126, 'macro avg': {'precision': 0.7727037874869631, 'recall': 0.8117522551668387, 'f1-score': 0.7859520847105, 'support': 1169}, 'weighted avg': {'precision': 0.8380509999925486, 'recall': 0.8186484174508126, 'f1-score': 0.8241581379205739, 'support': 1169}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.467800</td>\n",
              "      <td>0.464003</td>\n",
              "      <td>0.828058</td>\n",
              "      <td>{'0': {'precision': 0.5457875457875457, 'recall': 0.8514285714285714, 'f1-score': 0.6651785714285714, 'support': 175}, '1': {'precision': 0.9425742574257425, 'recall': 0.7652733118971061, 'f1-score': 0.84472049689441, 'support': 622}, '2': {'precision': 0.8772378516624041, 'recall': 0.9220430107526881, 'f1-score': 0.8990825688073394, 'support': 372}, 'accuracy': 0.8280581693755347, 'macro avg': {'precision': 0.7885332182918975, 'recall': 0.8462482980261218, 'f1-score': 0.8029938790434402, 'support': 1169}, 'weighted avg': {'precision': 0.862383652224163, 'recall': 0.8280581693755347, 'f1-score': 0.8351420997986768, 'support': 1169}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.191500</td>\n",
              "      <td>0.506073</td>\n",
              "      <td>0.821215</td>\n",
              "      <td>{'0': {'precision': 0.5480427046263345, 'recall': 0.88, 'f1-score': 0.6754385964912281, 'support': 175}, '1': {'precision': 0.948559670781893, 'recall': 0.7411575562700965, 'f1-score': 0.8321299638989169, 'support': 622}, '2': {'precision': 0.8582089552238806, 'recall': 0.9274193548387096, 'f1-score': 0.8914728682170542, 'support': 372}, 'accuracy': 0.8212147134302823, 'macro avg': {'precision': 0.7849371102107027, 'recall': 0.8495256370362686, 'f1-score': 0.7996804762023997, 'support': 1169}, 'weighted avg': {'precision': 0.8598505730361246, 'recall': 0.8212147134302823, 'f1-score': 0.8275573130092689, 'support': 1169}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.145900</td>\n",
              "      <td>0.588706</td>\n",
              "      <td>0.826347</td>\n",
              "      <td>{'0': {'precision': 0.5538461538461539, 'recall': 0.8228571428571428, 'f1-score': 0.6620689655172415, 'support': 175}, '1': {'precision': 0.9300970873786408, 'recall': 0.770096463022508, 'f1-score': 0.8425681618293756, 'support': 622}, '2': {'precision': 0.8705583756345178, 'recall': 0.9220430107526881, 'f1-score': 0.8955613577023498, 'support': 372}, 'accuracy': 0.8263473053892215, 'macro avg': {'precision': 0.7848338722864375, 'recall': 0.838332205544113, 'f1-score': 0.8000661616829889, 'support': 1169}, 'weighted avg': {'precision': 0.854825646713971, 'recall': 0.8263473053892215, 'f1-score': 0.8324108560210974, 'support': 1169}}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- RoBERTa Results ---\n",
            "Accuracy: 0.8280581693755347\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.85      0.67       175\n",
            "           1       0.94      0.77      0.84       622\n",
            "           2       0.88      0.92      0.90       372\n",
            "\n",
            "    accuracy                           0.83      1169\n",
            "   macro avg       0.79      0.85      0.80      1169\n",
            "weighted avg       0.86      0.83      0.84      1169\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/kaggle/input/financial-sentiment-analysis/data.csv')\n",
        "encoder = LabelEncoder()\n",
        "df['Sentiment'] = encoder.fit_transform(df['Sentiment'])\n",
        "\n",
        "# Split data\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df[['Sentence', 'Sentiment']].rename(columns={'Sentence': 'text', 'Sentiment': 'label'}))\n",
        "test_dataset = Dataset.from_pandas(test_df[['Sentence', 'Sentiment']].rename(columns={'Sentence': 'text', 'Sentiment': 'label'}))\n",
        "\n",
        "# Load RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Compute class weights\n",
        "class_counts = np.bincount(train_df['Sentiment'])\n",
        "total_samples = len(train_df)\n",
        "class_weights = total_samples / (3 * class_counts)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Custom Trainer with class weights\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get('labels')\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Define compute_metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    report = classification_report(labels, predictions, output_dict=True)\n",
        "    return {'accuracy': accuracy, 'report': report}\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=200,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=2e-5,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    report_to='none'\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Training model...\")\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate\n",
        "print(\"Evaluating model...\")\n",
        "eval_results = trainer.evaluate()\n",
        "accuracy = eval_results['eval_accuracy']\n",
        "print(f\"\\n--- RoBERTa Results ---\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Predict and get detailed report\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis=-1)\n",
        "y_test = test_dataset['label']\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "351736f0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T20:52:47.932343Z",
          "iopub.status.busy": "2025-04-08T20:52:47.932080Z",
          "iopub.status.idle": "2025-04-08T20:55:40.372076Z",
          "shell.execute_reply": "2025-04-08T20:55:40.371301Z"
        },
        "papermill": {
          "duration": 172.448169,
          "end_time": "2025-04-08T20:55:40.373432",
          "exception": false,
          "start_time": "2025-04-08T20:52:47.925263",
          "status": "completed"
        },
        "tags": [],
        "id": "351736f0",
        "outputId": "6d99fe68-65f6-4c8a-d3b5-cf5e5f57df8e",
        "colab": {
          "referenced_widgets": [
            "5f2f48c86afb4d1894f592ac8cc80da2",
            "e87045bef8e645d1887158fd34a6b238"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f2f48c86afb4d1894f592ac8cc80da2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2169 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e87045bef8e645d1887158fd34a6b238",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/543 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='680' max='680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [680/680 02:43, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.403300</td>\n",
              "      <td>0.242926</td>\n",
              "      <td>0.928177</td>\n",
              "      <td>{'0': {'precision': 0.8397790055248618, 'recall': 0.9382716049382716, 'f1-score': 0.8862973760932945, 'support': 162}, '1': {'precision': 0.9723756906077348, 'recall': 0.9238845144356955, 'f1-score': 0.9475100942126514, 'support': 381}, 'accuracy': 0.9281767955801105, 'macro avg': {'precision': 0.9060773480662982, 'recall': 0.9310780596869835, 'f1-score': 0.916903735152973, 'support': 543}, 'weighted avg': {'precision': 0.93281645859406, 'recall': 0.9281767955801105, 'f1-score': 0.9292477363206886, 'support': 543}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.306200</td>\n",
              "      <td>0.316286</td>\n",
              "      <td>0.944751</td>\n",
              "      <td>{'0': {'precision': 0.9342105263157895, 'recall': 0.8765432098765432, 'f1-score': 0.9044585987261147, 'support': 162}, '1': {'precision': 0.948849104859335, 'recall': 0.973753280839895, 'f1-score': 0.961139896373057, 'support': 381}, 'accuracy': 0.9447513812154696, 'macro avg': {'precision': 0.9415298155875622, 'recall': 0.9251482453582192, 'f1-score': 0.9327992475495859, 'support': 543}, 'weighted avg': {'precision': 0.9444817941336364, 'recall': 0.9447513812154696, 'f1-score': 0.9442294539811515, 'support': 543}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.077700</td>\n",
              "      <td>0.259561</td>\n",
              "      <td>0.952118</td>\n",
              "      <td>{'0': {'precision': 0.9146341463414634, 'recall': 0.9259259259259259, 'f1-score': 0.9202453987730062, 'support': 162}, '1': {'precision': 0.9683377308707124, 'recall': 0.963254593175853, 'f1-score': 0.9657894736842105, 'support': 381}, 'accuracy': 0.9521178637200737, 'macro avg': {'precision': 0.9414859386060879, 'recall': 0.9445902595508895, 'f1-score': 0.9430174362286083, 'support': 543}, 'weighted avg': {'precision': 0.9523156669780082, 'recall': 0.9521178637200737, 'f1-score': 0.952201738627829, 'support': 543}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.095900</td>\n",
              "      <td>0.324353</td>\n",
              "      <td>0.948435</td>\n",
              "      <td>{'0': {'precision': 0.935064935064935, 'recall': 0.8888888888888888, 'f1-score': 0.9113924050632912, 'support': 162}, '1': {'precision': 0.9537275064267352, 'recall': 0.973753280839895, 'f1-score': 0.9636363636363636, 'support': 381}, 'accuracy': 0.9484346224677717, 'macro avg': {'precision': 0.9443962207458352, 'recall': 0.9313210848643919, 'f1-score': 0.9375143843498275, 'support': 543}, 'weighted avg': {'precision': 0.9481596674569164, 'recall': 0.9484346224677717, 'f1-score': 0.948049768260972, 'support': 543}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.024700</td>\n",
              "      <td>0.261257</td>\n",
              "      <td>0.953959</td>\n",
              "      <td>{'0': {'precision': 0.9151515151515152, 'recall': 0.9320987654320988, 'f1-score': 0.9235474006116208, 'support': 162}, '1': {'precision': 0.9708994708994709, 'recall': 0.963254593175853, 'f1-score': 0.9670619235836627, 'support': 381}, 'accuracy': 0.9539594843462247, 'macro avg': {'precision': 0.9430254930254931, 'recall': 0.9476766793039759, 'f1-score': 0.9453046620976417, 'support': 543}, 'weighted avg': {'precision': 0.9542674841017382, 'recall': 0.9539594843462247, 'f1-score': 0.9540796902107884, 'support': 543}}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- RoBERTa Results (Class 1 Removed) ---\n",
            "Accuracy: 0.9539594843462247\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.92       162\n",
            "           1       0.97      0.96      0.97       381\n",
            "\n",
            "    accuracy                           0.95       543\n",
            "   macro avg       0.94      0.95      0.95       543\n",
            "weighted avg       0.95      0.95      0.95       543\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/kaggle/input/financial-sentiment-analysis/data.csv')\n",
        "\n",
        "# Remove Class 1 (neutral sentiment)\n",
        "df = df[df['Sentiment'] != 'neutral']\n",
        "# Encode labels (negative=0, positive=1)\n",
        "encoder = LabelEncoder()\n",
        "df['Sentiment'] = encoder.fit_transform(df['Sentiment'])\n",
        "\n",
        "# Split data\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df[['Sentence', 'Sentiment']].rename(columns={'Sentence': 'text', 'Sentiment': 'label'}))\n",
        "test_dataset = Dataset.from_pandas(test_df[['Sentence', 'Sentiment']].rename(columns={'Sentence': 'text', 'Sentiment': 'label'}))\n",
        "\n",
        "# Load RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)  # 2 classes: negative, positive\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Compute class weights (for 2 classes)\n",
        "class_counts = np.bincount(train_df['Sentiment'])\n",
        "total_samples = len(train_df)\n",
        "class_weights = total_samples / (2 * class_counts)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Custom Trainer with class weights\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get('labels')\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Define compute_metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    report = classification_report(labels, predictions, output_dict=True)\n",
        "    return {'accuracy': accuracy, 'report': report}\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=200,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=2e-5,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    report_to='none'\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Training model...\")\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate\n",
        "print(\"Evaluating model...\")\n",
        "eval_results = trainer.evaluate()\n",
        "accuracy = eval_results['eval_accuracy']\n",
        "print(f\"\\n--- RoBERTa Results (Class 1 Removed) ---\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Predict and get detailed report\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis=-1)\n",
        "y_test = test_dataset['label']\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 1918992,
          "sourceId": 3205803,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 10766.553753,
      "end_time": "2025-04-08T20:55:43.656411",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-08T17:56:17.102658",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}